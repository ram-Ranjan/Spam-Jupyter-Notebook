import pandas as pd
import sklearn 
import nltk




import pandas as pd
import re
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from typing import List, Dict, Any

class MessageFeatureExtractor:
    def __init__(self):
        # Define common patterns and keywords
        self.url_pattern = r'(?:https?://)?(?:[\w-]+\.)+[\w-]+(?:/[\w-]*)*'
        self.phone_pattern = r'[\+]?[\d][\d\-]{9,}'
        self.currency_pattern = r'(?:₹|RS|INR|\$)\s*\d+(?:,\d+)*(?:\.\d{2})?'
        
        # Define keyword lists
        self.urgency_words = [
            'जल्दी', 'आज', 'कल', 'अंतिम', 'मौका', 'शीघ्र', 'टाइम', 'समय',
            'लिमिटेड', 'ऑफर', 'छूट', 'डिस्काउंट', 'बचत'
        ]
        
        self.action_words = [
            'करें', 'पाएं', 'खरीदें', 'क्लिक', 'अभी', 'देखें', 'कॉल',
            'संपर्क', 'रजिस्टर', 'साइन अप', 'डाउनलोड'
        ]
        
        self.spam_words = [
            'फ्री', 'मुफ्त', 'विजेता', 'इनाम', 'लकी', 'बधाई', 'जीत',
            'कैश बैक', 'बोनस', 'धमाका', 'ऑफर'
        ]
        
        # Initialize TF-IDF vectorizer
        self.tfidf = TfidfVectorizer(max_features=100)

    def count_words(self, text: str) -> int:
        """Count words in the text"""
        return len(text.split())

    def check_pattern_presence(self, text: str, pattern: str) -> int:
        """Check if a regex pattern exists in text"""
        return int(bool(re.search(pattern, text)))

    def check_keywords_presence(self, text: str, keywords: List[str]) -> int:
        """Check if any keyword from the list exists in text"""
        return int(any(word in text for word in keywords))

    def extract_features(self, messages: List[str]) -> pd.DataFrame:
        """Extract all features from messages"""
        features = []
        
        # Calculate TF-IDF scores once for all messages
        tfidf_matrix = self.tfidf.fit_transform(messages)
        tfidf_scores = np.mean(tfidf_matrix.toarray(), axis=1)
        
        for idx, message in enumerate(messages):
            feature_dict = {
                'word_count': self.count_words(message),
                'has_link': self.check_pattern_presence(message, self.url_pattern),
                'has_phone': self.check_pattern_presence(message, self.phone_pattern),
                'has_currency': self.check_pattern_presence(message, self.currency_pattern),
                'has_urgency': self.check_keywords_presence(message, self.urgency_words),
                'has_action': self.check_keywords_presence(message, self.action_words),
                'has_spam_words': self.check_keywords_presence(message, self.spam_words),
                'tfidf_score': tfidf_scores[idx]
            }
            features.append(feature_dict)
        
        return pd.DataFrame(features)

def main():
    # 1. Load your data
    # Replace 'your_file.csv' with your actual file path
    df = pd.read_csv('Spam_Ham_hindi.csv')
    
    # 2. Initialize the feature extractor
    extractor = MessageFeatureExtractor()
    
    # 3. Extract features
    features_df = extractor.extract_features(df['Message'].tolist())
    
    # 4. Combine with original data
    result_df = pd.concat([df, features_df], axis=1)
    
    # 5. Save to Excel
    result_df.to_excel('message_features.xlsx', index=False)
    
    # 6. Print feature statistics
    print("\nFeature Statistics:")
    print(features_df.describe())
    
    # 7. Print sample of first few rows
    print("\nSample of extracted features:")
    print(features_df.head())

if __name__ == "__main__":
    main()


import pandas as pd
import re
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from typing import List, Dict, Any

class MessageFeatureExtractor:
    def __init__(self):
        # Define common patterns and keywords
        self.url_pattern = r'(?:https?://)?(?:[\w-]+\.)+[\w-]+(?:/[\w-]*)*'
        self.phone_pattern = r'[\+]?[\d][\d\-]{9,}'
        self.currency_pattern = r'(?:₹|RS|INR|\$)\s*\d+(?:,\d+)*(?:\.\d{2})?'
        
        # Define keyword lists
        self.urgency_words = [
            'जल्दी', 'आज', 'कल', 'अंतिम', 'मौका', 'शीघ्र', 'टाइम', 'समय',
            'लिमिटेड', 'ऑफर', 'छूट', 'डिस्काउंट', 'बचत'
        ]
        
        self.action_words = [
            'करें', 'पाएं', 'खरीदें', 'क्लिक', 'अभी', 'देखें', 'कॉल',
            'संपर्क', 'रजिस्टर', 'साइन अप', 'डाउनलोड'
        ]
        
        self.spam_words = [
            'फ्री', 'मुफ्त', 'विजेता', 'इनाम', 'लकी', 'बधाई', 'जीत',
            'कैश बैक', 'बोनस', 'धमाका', 'ऑफर'
        ]
        
        # Initialize TF-IDF vectorizer
        self.tfidf = TfidfVectorizer(max_features=100)

    def count_words(self, text: str) -> int:
        """Count words in the text"""
        return len(text.split())

    def check_pattern_presence(self, text: str, pattern: str) -> int:
        """Check if a regex pattern exists in text"""
        return int(bool(re.search(pattern, text)))

    def check_keywords_presence(self, text: str, keywords: List[str]) -> int:
        """Check if any keyword from the list exists in text"""
        return int(any(word in text for word in keywords))

    def extract_features(self, messages: List[str]) -> pd.DataFrame:
        """Extract all features from messages"""
        features = []
        
        # Calculate TF-IDF scores once for all messages
        tfidf_matrix = self.tfidf.fit_transform(messages)
        tfidf_scores = np.mean(tfidf_matrix.toarray(), axis=1)
        
        for idx, message in enumerate(messages):
            feature_dict = {
                'word_count': self.count_words(message),
                'has_link': self.check_pattern_presence(message, self.url_pattern),
                'has_phone': self.check_pattern_presence(message, self.phone_pattern),
                'has_currency': self.check_pattern_presence(message, self.currency_pattern),
                'has_urgency': self.check_keywords_presence(message, self.urgency_words),
                'has_action': self.check_keywords_presence(message, self.action_words),
                'has_spam_words': self.check_keywords_presence(message, self.spam_words),
                'tfidf_score': tfidf_scores[idx]
            }
            features.append(feature_dict)
        
        return pd.DataFrame(features)

def encode_category(category: str) -> int:
    """
    Encode category to binary (spam=0, ham=1)
    """
    return 1 if category.lower() == 'ham' else 0

def main():
    # 1. Load your data
    # Replace 'your_file.csv' with your actual file path
    df = pd.read_csv('Spam_Ham_hindi.csv')
    
    # 2. Initialize the feature extractor
    extractor = MessageFeatureExtractor()
    
    # 3. Extract features
    features_df = extractor.extract_features(df['Message'].tolist())
    
    # 4. Encode categories
    df['category_label'] = df['Category'].apply(encode_category)
    
    # 5. Combine with original data
    result_df = pd.concat([
        df[['Message', 'Category', 'category_label']], 
        features_df
    ], axis=1)
    
    # 6. Save to Excel
    result_df.to_excel('message_features2.xlsx', index=False)
    
    # 7. Print feature statistics
    print("\nFeature Statistics:")
    print(features_df.describe())
    
    # 8. Print sample of first few rows with labels
    print("\nSample of extracted features with labels:")
    print(result_df[['Category', 'category_label'] + list(features_df.columns)].head())
    
    # 9. Print label distribution
    print("\nLabel Distribution:")
    print(result_df['category_label'].value_counts())

if __name__ == "__main__":
    main()



